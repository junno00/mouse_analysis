{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm, tqdm_notebook, tnrange\n",
    "\n",
    "import shutil\n",
    "\n",
    "from scipy.misc import imresize\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Conv2D, UpSampling2D, Lambda\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import backend as K\n",
    "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras import initializers, layers, models\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras import callbacks\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.noise import GaussianDropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some parameters\n",
    "im_width = 256\n",
    "im_height = 256\n",
    "im_chan = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3924it [00:26, 126.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "x_train (3139, 256, 256, 3)\n",
      "x_test (785, 256, 256, 3)\n",
      "y_train (3139, 256, 256, 3)\n",
      "y_test (785, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "# 画像のsizeは256*256\n",
    "\n",
    "# imgの入ってるディレクトリのpathを入れる\n",
    "train_crop_img_path = sorted(list(Path(\"/Users/junno00/Desktop/dataset/ori_train_cropped_2\").glob(\"*\")))\n",
    "# maskの入ってるディレクトリのpathを入れる\n",
    "train_crop_mask_path = sorted(list(Path(\"/Users/junno00/Desktop/dataset/anno_train_cropped_2\").glob(\"*\")))\n",
    "\n",
    "X_train = np.zeros((len(train_crop_img_path), im_height, im_width, im_chan), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_crop_mask_path), im_height, im_width, im_chan), dtype=np.uint8)\n",
    "\n",
    "for i, (train_img, train_mask)  in tqdm(enumerate(zip(train_crop_img_path, train_crop_mask_path))):\n",
    "    X_train[i] = np.array(load_img(train_img), dtype=np.float32)\n",
    "    Y_train[i] = np.array(load_img(train_mask), dtype=np.float32)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.2)\n",
    "print('\\nx_train',x_train.shape)\n",
    "print('x_test',x_test.shape)\n",
    "print('y_train',y_train.shape)\n",
    "print('y_test',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hoge' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-c9a5626644ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mplotTrainData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-c9a5626644ea>\u001b[0m in \u001b[0;36mplotTrainData\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplotTrainData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhoge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#hogeを出力したい枚数に変更\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X_train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hoge' is not defined"
     ]
    }
   ],
   "source": [
    "def plotTrainData(a,b):\n",
    "    for i in range(hoge): #hogeを出力したい枚数(int)に変更\n",
    "        ix = random.randint(0, len(X_train))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.title(\"X_train\")\n",
    "        imshow(a[ix])\n",
    "        plt.axis('off')\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.title(\"Y_train\")\n",
    "        imshow(np.squeeze(b[ix]))\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "plotTrainData(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics and plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsCheckpoint(Callback):\n",
    "    \"\"\"Callback that saves metrics after each epoch\"\"\"\n",
    "    def __init__(self, savepath):\n",
    "        super(MetricsCheckpoint, self).__init__()\n",
    "        self.savepath = savepath\n",
    "        self.history = {}\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        np.save(self.savepath, self.history)\n",
    "\n",
    "def plotKerasLearningCurve():\n",
    "    plt.figure(figsize=(10,5))\n",
    "    metrics = np.load('logs.npy')[()]\n",
    "    filt = ['acc'] # try to add 'loss' to see the loss learning curve\n",
    "    for k in filter(lambda x : np.any([kk in x for kk in filt]), metrics.keys()):\n",
    "        l = np.array(metrics[k])\n",
    "        plt.plot(l, c= 'r' if 'val' not in k else 'b', label='val' if 'val' in k else 'train')\n",
    "        x = np.argmin(l) if 'loss' in k else np.argmax(l)\n",
    "        y = l[x]\n",
    "        plt.scatter(x,y, lw=0, alpha=0.25, s=100, c='r' if 'val' not in k else 'b')\n",
    "        plt.text(x, y, '{} = {:.4f}'.format(x,y), size='15', color= 'r' if 'val' not in k else 'b')   \n",
    "    plt.legend(loc=4)\n",
    "    plt.axis([0, None, None, None]);\n",
    "    plt.grid()\n",
    "    plt.xlabel('Number of epochs')\n",
    "\n",
    "def plot_learning_curve(history):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig('./accuracy_curve.png')\n",
    "    #plt.clf()\n",
    "    # summarize history for loss\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig('./loss_curve.png')\n",
    "\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)\n",
    "\n",
    "# Custom loss function\n",
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return 0.5 * keras.losses.binary_crossentropy(y_true, y_pred) - dice_coef(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_unit(input_tensor, stage, nb_filter, kernel_size=3):\n",
    "\n",
    "    x = Conv2D(nb_filter, (kernel_size, kernel_size), activation=act, name='conv'+stage+'_1', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=l2(1e-4))(input_tensor)\n",
    "    x = Dropout(dropout_rate, name='dp'+stage+'_1')(x)\n",
    "    x = Conv2D(nb_filter, (kernel_size, kernel_size), activation=act, name='conv'+stage+'_2', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=l2(1e-4))(x)\n",
    "    x = Dropout(dropout_rate, name='dp'+stage+'_2')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 1.\n",
    "dropout_rate = 0.5\n",
    "act = \"relu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def U_Net(a, b, c, d):\n",
    "    inputs = Input((im_height, im_width, im_chan))\n",
    "\n",
    "    nb_filter = [8,16,32,64,128]\n",
    "    \n",
    "    input_tensor = Lambda(lambda x: x / 255) (inputs)\n",
    "\n",
    "    conv1_1 = standard_unit(input_tensor, stage='11', nb_filter=nb_filter[0])\n",
    "    pool1 = MaxPooling2D((2, 2), strides=(2, 2), name='pool1')(conv1_1)\n",
    "\n",
    "    conv2_1 = standard_unit(pool1, stage='21', nb_filter=nb_filter[1])\n",
    "    pool2 = MaxPooling2D((2, 2), strides=(2, 2), name='pool2')(conv2_1)\n",
    "\n",
    "    conv3_1 = standard_unit(pool2, stage='31', nb_filter=nb_filter[2])\n",
    "    pool3 = MaxPooling2D((2, 2), strides=(2, 2), name='pool3')(conv3_1)\n",
    "\n",
    "    conv4_1 = standard_unit(pool3, stage='41', nb_filter=nb_filter[3])\n",
    "    pool4 = MaxPooling2D((2, 2), strides=(2, 2), name='pool4')(conv4_1)\n",
    "\n",
    "    conv5_1 = standard_unit(pool4, stage='51', nb_filter=nb_filter[4])\n",
    "\n",
    "    up4_2 = Conv2DTranspose(nb_filter[3], (2, 2), strides=(2, 2), name='up42', padding='same')(conv5_1)\n",
    "    conv4_2 = concatenate([up4_2, conv4_1], name='merge42', axis=bn_axis)\n",
    "    conv4_2 = standard_unit(conv4_2, stage='42', nb_filter=nb_filter[3])\n",
    "\n",
    "    up3_3 = Conv2DTranspose(nb_filter[2], (2, 2), strides=(2, 2), name='up33', padding='same')(conv4_2)\n",
    "    conv3_3 = concatenate([up3_3, conv3_1], name='merge33', axis=bn_axis)\n",
    "    conv3_3 = standard_unit(conv3_3, stage='33', nb_filter=nb_filter[2])\n",
    "\n",
    "    up2_4 = Conv2DTranspose(nb_filter[1], (2, 2), strides=(2, 2), name='up24', padding='same')(conv3_3)\n",
    "    conv2_4 = concatenate([up2_4, conv2_1], name='merge24', axis=bn_axis)\n",
    "    conv2_4 = standard_unit(conv2_4, stage='24', nb_filter=nb_filter[1])\n",
    "\n",
    "    up1_5 = Conv2DTranspose(nb_filter[0], (2, 2), strides=(2, 2), name='up15', padding='same')(conv2_4)\n",
    "    conv1_5 = concatenate([up1_5, conv1_1], name='merge15', axis=bn_axis)\n",
    "    conv1_5 = standard_unit(conv1_5, stage='15', nb_filter=nb_filter[0])\n",
    "\n",
    "    outputs = Conv2D(3, (1, 1), activation='sigmoid', name='output', kernel_initializer = 'he_normal', padding='same', kernel_regularizer=l2(1e-4))(conv1_5)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    # model compile\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou,'accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    earlystopper = EarlyStopping(patience=5, verbose=1)\n",
    "    checkpointer = ModelCheckpoint(filepath=\"model.ep{epoch:02d}.h5\", verbose=1, save_best_only=True)\n",
    "    results = model.fit(a,b,batch_size=16,epochs=40,validation_data=(c,d))\n",
    "    plot_learning_curve(results)\n",
    "    plt.show()\n",
    "    plotKerasLearningCurve()\n",
    "    plt.show()\n",
    "    global modelZ\n",
    "    modelZ = model\n",
    "    return modelZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junno00/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/keras/layers/core.py:661: UserWarning: `output_shape` argument not specified for layer lambda_5 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 256, 256, 3)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "In `Conv2DTranspose`, with padding mode `same`, even kernel sizes are not supported with Theano. You can set `kernel_size` to an odd number.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-155f178275da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mU_Net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-838c4e682b67>\u001b[0m in \u001b[0;36mU_Net\u001b[0;34m(a, b, c, d)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mconv5_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandard_unit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'51'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_filter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mup4_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2DTranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_filter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'up42'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv5_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mconv4_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mup4_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv4_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'merge42'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbn_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mconv4_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandard_unit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv4_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'42'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_filter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m             data_format=self.data_format)\n\u001b[0m\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36mconv2d_transpose\u001b[0;34m(x, kernel, output_shape, strides, padding, data_format)\u001b[0m\n\u001b[1;32m   2037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2038\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'same'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkernel_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2039\u001b[0;31m         raise ValueError('In `Conv2DTranspose`, with padding mode `same`, '\n\u001b[0m\u001b[1;32m   2040\u001b[0m                          \u001b[0;34m'even kernel sizes are not supported with Theano. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2041\u001b[0m                          'You can set `kernel_size` to an odd number.')\n",
      "\u001b[0;31mValueError\u001b[0m: In `Conv2DTranspose`, with padding mode `same`, even kernel sizes are not supported with Theano. You can set `kernel_size` to an odd number."
     ]
    }
   ],
   "source": [
    "U_Net(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPredictions(a,b,c,d,e):\n",
    "    model = e\n",
    "    # Threshold predictions\n",
    "    preds_train = model.predict(a[:int(a.shape[0]*0.9)], verbose=1)\n",
    "    preds_val = model.predict(a[int(a.shape[0]*0.9):], verbose=1)\n",
    "    preds_test = model.predict(c, verbose=1)\n",
    "    preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "    preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
    "    preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "    # Perform a sanity check on some random training samples\n",
    "    ix = random.randint(0, len(preds_train_t))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title(\"X_train\")\n",
    "    plt.axis('off')\n",
    "    imshow(a[ix])\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title(\"Y_train\")\n",
    "    plt.axis('off')\n",
    "    imshow(np.squeeze(b[ix]))\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.axis('off')\n",
    "    imshow(np.squeeze(preds_train_t[ix]))\n",
    "    plt.show()\n",
    "    # Perform a sanity check on some random validation samples\n",
    "    ix = random.randint(0, len(preds_val_t))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title(\"X_test\")\n",
    "    plt.axis('off')\n",
    "    imshow(a[int(a.shape[0]*0.9):][ix])\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title(\"Y_test\")\n",
    "    plt.axis('off')\n",
    "    imshow(np.squeeze(b[int(b.shape[0]*0.9):][ix]))\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.axis('off')\n",
    "    imshow(np.squeeze(preds_val_t[ix]))\n",
    "    plt.show()\n",
    "plotPredictions(x_train,y_train,x_test,y_test,modelZ)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
